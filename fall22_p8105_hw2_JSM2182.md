Homework 2
================
Jennifer Mizhquiri Barbecho

# Problem 1 (provided solution)

Below we import and clean data from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with
data import, updates variable names, and selects the columns that will
be used in later parts fo this problem. We update `entry` from `yes` /
`no` to a logical variable. As part of data import, we specify that
`Route` columns 8-11 should be character for consistency with 1-7.

``` r
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations.

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

*Step 1: Read and clean Mr. Trash Wheel dataset*

-   variable names are cleaned
-   rows not containing dumpster values are removed
-   note that “dumpster” is a numeric variable
-   sports_ball is rounded/set to an integer
-   note that year has been changed to an integer
-   a variable “wheel” with value of “mr” has been applied to all obs,
    to facilitate tracking after merging.

*Step 2: Professor Trashwheel dataset*

-   variable names are cleaned
-   rows not containing dumpster values are removed
-   a variable “wheel” with value of “prof” has been applied to all obs,
    to facilitate tracking and later merging
-   note that sports balls is NOT included as a variable
-   note that dumpster variable is a numeric variable
-   note that year is an integer

*Step 3: Combining Mr. Trash Wheel & Professor Trash Wheel Dataset*

-   Combine both datasets into a dataset called “combo_wheels_tidy”

-   About the Dataset:

``` r
head(combo_wheels_tidy)
```

    ## # A tibble: 6 × 15
    ##   dumpster month  year date                weight_tons volume_…¹ plast…² polys…³
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>     <dbl>   <dbl>   <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31        18    1450    1820
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74        13    1120    1030
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45        15    2450    3100
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1         15    2380    2730
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06        18     980     870
    ## 6        6 May    2014 2014-05-20 00:00:00        2.71        13    1430    2140
    ## # … with 7 more variables: cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, wheel <chr>, and abbreviated variable names
    ## #   ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

There are 641 observations in the resulting dataset. This dataset
demonstrates various categories of collected items (i.e. sports balls,
glass bottles, trash bottles) by weight (in tons), across years (2014 -
2022), for a trash-collection, water-vessel based initiative. This is
helpful for generating summary stats on output and can help compare
productivity between Mr. Trashwheels and Professor Trashwheels. For
example, Mr. Trashwheel collected 190.12 tons, and in the year 2020,
Mr. Trashwheels collected 856 sports balls.

# Problem 3

*Cleaning Dataset 1: Presidential and Congressional Parties by Year*

Import and clean pols-month.csv

-   note: data is sorted by year and month with month set as a factor
    and year set as an integer
-   year and month were moved to become the leading columns
-   month is a factor variable and each value is renamed/reset to their
    corresponding month
-   president variable was created to denote affiliation (i.e. dem =
    Democrat; gop = GOP)
-   there is an aberration in the data. In most cases prez_gop and
    prez_dem could be considered binary variables (0 = no, 1 = yes),
    however there is a case of 2 from August 1974 until January 1975.
    This is likely due to Nixon’s resignation in which there were “2”
    presidents who occupied the given year and who were republicans.
-   This may require further inspection and as such the dummy variable
    was ultimately retained

``` r
head(pols_df)
```

    ## # A tibble: 6 × 10
    ##    year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president dummy
    ##   <int> <fct>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ## 1  1947 January       23      51     253      23      45     198 dem           1
    ## 2  1947 February      23      51     253      23      45     198 dem           1
    ## 3  1947 March         23      51     253      23      45     198 dem           1
    ## 4  1947 April         23      51     253      23      45     198 dem           1
    ## 5  1947 May           23      51     253      23      45     198 dem           1
    ## 6  1947 June          23      51     253      23      45     198 dem           1

*Cleaning Dataset 2: SNP*

Import and clean snp.csv

-   note: data is sorted by year and month
-   year and month were moved to become the leading columns
-   month is a factor variable and each value is renamed/reset to their
    corresponding month

``` r
head(snp_df)
```

    ## # A tibble: 6 × 3
    ##    year month    close
    ##   <dbl> <fct>    <dbl>
    ## 1  1950 January   17.0
    ## 2  1950 February  17.2
    ## 3  1950 March     17.3
    ## 4  1950 April     18.0
    ## 5  1950 May       18.8
    ## 6  1950 June      17.7

*Cleaning Dataset 3: Unemployment*

-   note: data is sorted by year and month
-   year and month were moved to become the leading columns
-   month is a factor variable and each value is renamed/reset to their
    corresponding month

``` r
head(unemp_df)
```

    ## # A tibble: 6 × 3
    ##    year month    unemp_freq
    ##   <int> <fct>         <dbl>
    ## 1  1948 January         3.4
    ## 2  1948 February        3.8
    ## 3  1948 March           4  
    ## 4  1948 April           3.9
    ## 5  1948 May             3.5
    ## 6  1948 June            3.6

*Joining SNP TO POLS* \* in which pols is the given x data set with 10
columns \* in which snp is the given y data set with 3 columns

*Joining unemployment to the SNP/POLS merged dataset*

*Combined dataset*

``` r
head(pols_snp_unemp_df)
```

    ## # A tibble: 6 × 12
    ##    year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president dummy
    ##   <dbl> <fct>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ## 1  1947 January       23      51     253      23      45     198 dem           1
    ## 2  1947 February      23      51     253      23      45     198 dem           1
    ## 3  1947 March         23      51     253      23      45     198 dem           1
    ## 4  1947 April         23      51     253      23      45     198 dem           1
    ## 5  1947 May           23      51     253      23      45     198 dem           1
    ## 6  1947 June          23      51     253      23      45     198 dem           1
    ## # … with 2 more variables: close <dbl>, unemp_freq <dbl>

The resulting combined dataset is 12 columns by 822 rows. The year span
is 1947 to 2015. Key data include the frequency of senators, governors,
and representatives by party affiliation, the party affiliation of the
president, the close number, and the unemployment rates, all by year and
month.
